import type { Model } from "./types.js";

export const MODELS = {
    openai: {
		"gpt-5.2": {
			id: "gpt-5.2",
			name: "GPT-5.2",
			api: "openai",
			baseUrl: "https://api.openai.com/v1",
			reasoning: true,
			input: ["text", "image", "file"],
			cost: {
				input: 1.75,
				output: 14,
				cacheRead: 0.175,
				cacheWrite: 0,
			},
			contextWindow: 400000,
			maxTokens: 128000,
		} satisfies Model<"openai">,
		"gpt-5.2-pro": {
			id: "gpt-5.2-pro",
			name: "GPT-5.2 Pro",
			api: "openai",
			baseUrl: "https://api.openai.com/v1",
			reasoning: true,
			input: ["text", "image", "file"],
			cost: {
				input: 21,
				output: 168,
				cacheRead: 21,
				cacheWrite: 0,
			},
			contextWindow: 400000,
			maxTokens: 128000,
		} satisfies Model<"openai">,
		"gpt-5.1-codex-max": {
			id: "gpt-5.1-codex-max",
			name: "GPT-5.1 Codex Max",
			api: "openai",
			baseUrl: "https://api.openai.com/v1",
			reasoning: true,
			input: ["text", "image", "file"],
			cost: {
				input: 1.25,
				output: 10,
				cacheRead: 0.125,
				cacheWrite: 0,
			},
			contextWindow: 400000,
			maxTokens: 128000,
		} satisfies Model<"openai">,
		"gpt-5-mini": {
			id: "gpt-5-mini",
			name: "GPT-5 Mini",
			api: "openai",
			baseUrl: "https://api.openai.com/v1",
			reasoning: true,
			input: ["text", "image", "file"],
			cost: {
				input: 0.25,
				output: 2,
				cacheRead: 0.025,
				cacheWrite: 0,
			},
			contextWindow: 400000,
			maxTokens: 128000,
		} satisfies Model<"openai">,
		"gpt-5-nano": {
			id: "gpt-5-nano",
			name: "GPT-5 Nano",
			api: "openai",
			baseUrl: "https://api.openai.com/v1",
			reasoning: true,
			input: ["text", "image", "file"],
			cost: {
				input: 0.05,
				output: 0.4,
				cacheRead: 0.005,
				cacheWrite: 0,
			},
			contextWindow: 400000,
			maxTokens: 128000,
		} satisfies Model<"openai">,
		"gpt-5": {
			id: "gpt-5",
			name: "GPT-5",
			api: "openai",
			baseUrl: "https://api.openai.com/v1",
			reasoning: true,
			input: ["text", "image", "file"],
			cost: {
				input: 1.25,
				output: 10,
				cacheRead: 0.125,
				cacheWrite: 0,
			},
			contextWindow: 400000,
			maxTokens: 128000,
		} satisfies Model<"openai">,
    }
}